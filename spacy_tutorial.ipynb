{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from spacy.en import English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parser = English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "multi_sentence = \"There is an art, it says, or rather, a knack to flying.\" \\\n",
    "                 \"The knack lies in learning how to throw yourself at the ground and miss.\" \\\n",
    "                 \"In the beginning the Universe was created. This has made a lot of people \"\\\n",
    "                 \"very angry and been widely regarded as a bad move.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parsed_data = parser(unicode(multi_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('original:', 640, u'There')\n",
      "('lowercased:', 530, u'there')\n",
      "('lemma:', 530, u'there')\n",
      "('shape:', 489815, u'Xxxxx')\n",
      "('prefix:', 2907, u'T')\n",
      "('suffix:', 48458, u'ere')\n",
      "('log probability:', -7.347356796264648)\n",
      "('Brown cluster id:', 1918)\n",
      "----------------------------------------\n",
      "('original:', 474, u'is')\n",
      "('lowercased:', 474, u'is')\n",
      "('lemma:', 488, u'be')\n",
      "('shape:', 21581, u'xx')\n",
      "('prefix:', 570, u'i')\n",
      "('suffix:', 474, u'is')\n",
      "('log probability:', -4.457748889923096)\n",
      "('Brown cluster id:', 762)\n",
      "----------------------------------------\n",
      "('original:', 523, u'an')\n",
      "('lowercased:', 523, u'an')\n",
      "('lemma:', 523, u'an')\n",
      "('shape:', 21581, u'xx')\n",
      "('prefix:', 469, u'a')\n",
      "('suffix:', 523, u'an')\n",
      "('log probability:', -6.014852046966553)\n",
      "('Brown cluster id:', 3)\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i, token in enumerate(parsed_data):\n",
    "    print(\"original:\", token.orth, token.orth_)\n",
    "    print(\"lowercased:\", token.lower, token.lower_)\n",
    "    print(\"lemma:\", token.lemma, token.lemma_)\n",
    "    print(\"shape:\", token.shape, token.shape_)\n",
    "    print(\"prefix:\", token.prefix, token.prefix_)\n",
    "    print(\"suffix:\", token.suffix, token.suffix_)\n",
    "    print(\"log probability:\", token.prob)\n",
    "    print(\"Brown cluster id:\", token.cluster)\n",
    "    print(\"----------------------------------------\")\n",
    "    if i > 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is an art, it says, or rather, a knack to flying.\n",
      "The knack lies in learning how to throw yourself at the ground and miss.\n",
      "In the beginning the Universe was created.\n",
      "This has made a lot of people very angry and been widely regarded as a bad move.\n"
     ]
    }
   ],
   "source": [
    "# DISPLAY SENTENCES\n",
    "sents = []\n",
    "for span in parsed_data.sents:\n",
    "    sent = ''.join(parsed_data[i].string for i in range(span.start,span.end)).strip()\n",
    "    sents.append(sent)\n",
    "for sentence in sents:\n",
    "    print sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There ADV\n",
      "is VERB\n",
      "an DET\n",
      "art NOUN\n",
      ", PUNCT\n",
      "it PRON\n",
      "says VERB\n",
      ", PUNCT\n",
      "or CONJ\n",
      "rather ADV\n",
      ", PUNCT\n",
      "a DET\n",
      "knack NOUN\n",
      "to ADP\n",
      "flying NOUN\n",
      ". PUNCT\n"
     ]
    }
   ],
   "source": [
    "# PART-OF-SPEECH TAGGING\n",
    "for span in parsed_data.sents:\n",
    "    sent = [parsed_data[i] for i in range(span.start,span.end)]\n",
    "    break\n",
    "\n",
    "for token in sent:\n",
    "    print token.orth_, token.pos_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The det boy [] []\n",
      "boy nsubj ran [u'The'] [u'with']\n",
      "with prep boy [] [u'dog']\n",
      "the det dog [] []\n",
      "spotted amod dog [] []\n",
      "dog pobj with [u'the', u'spotted'] []\n",
      "quickly advmod ran [] []\n",
      "ran ROOT ran [u'boy', u'quickly'] [u'after', u'.']\n",
      "after prep ran [] [u'firetruck']\n",
      "the det firetruck [] []\n",
      "firetruck pobj after [u'the'] []\n",
      ". punct ran [] []\n"
     ]
    }
   ],
   "source": [
    "# DEPENDENCIES\n",
    "example = u\"The boy with the spotted dog quickly ran after the firetruck.\"\n",
    "parsed_example = parser(example)\n",
    "for token in parsed_example:\n",
    "    print token.orth_, token.dep_, token.head.orth_, \\\n",
    "         [t.orth_ for t in token.lefts], [t.orth_ for t in token.rights]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple ORG\n",
      "'s (not an entity)\n",
      "stocks (not an entity)\n",
      "dropped (not an entity)\n",
      "dramatically (not an entity)\n",
      "after (not an entity)\n",
      "the (not an entity)\n",
      "death (not an entity)\n",
      "of (not an entity)\n",
      "Steve PERSON\n",
      "Jobs PERSON\n",
      "in (not an entity)\n",
      "October DATE\n",
      ". (not an entity)\n",
      "----------------- entities only -----------------\n",
      "349 ORG Apple\n",
      "346 PERSON Steve Jobs\n",
      "356 DATE October\n"
     ]
    }
   ],
   "source": [
    "# NAMED ENTITY RECOGNITION\n",
    "example = u\"Apple's stocks dropped dramatically after the death of Steve Jobs in October.\"\n",
    "parsed_example = parser(example)\n",
    "for token in parsed_example:\n",
    "    print token.orth_, token.ent_type_ if token.ent_type_ != \"\" else \"(not an entity)\"\n",
    "    \n",
    "print \"----------------- entities only -----------------\"\n",
    "ents = list(parsed_example.ents)\n",
    "for entity in ents:\n",
    "    print entity.label, entity.label_, ' '.join(t.orth_ for t in entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lol NOUN lol\n",
      "that ADJ that\n",
      "is VERB be\n",
      "rly ADV rly\n",
      "funny ADJ funny\n",
      ":) PUNCT :)\n",
      "This DET this\n",
      "is VERB be\n",
      "gr8 VERB gr8\n",
      "i PRON i\n",
      "rate VERB rate\n",
      "it PRON it\n",
      "8/8 NUM 8/8\n",
      "! PUNCT !\n",
      "! PUNCT !\n",
      "! PUNCT !\n"
     ]
    }
   ],
   "source": [
    "# PARSING MESSY DATA\n",
    "messy_data = u\"lol that is rly funny :) This is gr8 i rate it 8/8!!!\"\n",
    "parsed_data = parser(messy_data)\n",
    "for token in parsed_data:\n",
    "    print token.orth_, token.pos_, token.lemma_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 most similar words to NASA\n",
      "nasa\n",
      "jpl\n",
      "noaa\n",
      "darpa\n",
      "esa\n",
      "cern\n",
      "nih\n",
      "norad\n",
      "spacex\n",
      "fema\n"
     ]
    }
   ],
   "source": [
    "# WORD EMBEDDINGS AND SIMILARITY\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "nasa = parser.vocab[u'NASA']\n",
    "\n",
    "cosine = lambda v1, v2: dot(v1,v2) / (norm(v1)*norm(v2))\n",
    "\n",
    "all_words = [w for w in parser.vocab\n",
    "             if w.has_vector and w.orth_.islower() and w.lower_ != u'NASA']\n",
    "\n",
    "all_words.sort(key=lambda w: cosine(w.vector,nasa.vector), reverse=True)\n",
    "print \"Top 10 most similar words to NASA\"\n",
    "for word in all_words[:10]:\n",
    "    print word.orth_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------\n",
      "Top 3 closest results for king - man + woman:\n",
      "queen\n",
      "norodom\n",
      "hrh\n"
     ]
    }
   ],
   "source": [
    "# WORD VECTOR ALGEBRA\n",
    "king = parser.vocab[u'king']\n",
    "man = parser.vocab[u'man']\n",
    "woman = parser.vocab[u'queen']\n",
    "\n",
    "result = king.vector - man.vector + woman.vector\n",
    "\n",
    "all_words = [w for w in parser.vocab\n",
    "             if w.has_vector and w.orth_.islower() \n",
    "                             and w.lower_ not in ['king','man','woman']]\n",
    "all_words.sort(key=lambda w: cosine(w.vector,result), reverse=True)\n",
    "print '\\n-----------------------\\nTop 3 closest results for king - man + woman:'\n",
    "for word in all_words[:3]:\n",
    "    print word.orth_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
